<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title></title>
		<description>An elder's memo.</description>
		<link>/</link>
		<atom:link href="/feed.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>ipython parallel</title>
				<description>&lt;p&gt;IPython 3.x&lt;/p&gt;
&lt;h2 id=&quot;architecture-overview&quot;&gt;Architecture overview&lt;/h2&gt;
&lt;figure&gt;
&lt;img src=&quot;/assets/images/28.png&quot; alt=&quot;&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The IPython architecture consists of four components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The IPython engine.&lt;/li&gt;
&lt;li&gt;The IPython hub.&lt;/li&gt;
&lt;li&gt;The IPython schedulers.&lt;/li&gt;
&lt;li&gt;The controller client.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These components live in the &lt;code&gt;IPython.parallel&lt;/code&gt; package and are installed with IPython.&lt;/p&gt;
&lt;h2 id=&quot;getting-started&quot;&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;To use IPython for parallel computing, you need to start one instance of the controller and one or more instances of the engine. Initially, it is best to simply start a controller and engines on a single host using the &lt;code&gt;ipcluster&lt;/code&gt; command. To start a controller and 4 engines on your localhost, just do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ipcluster start -n 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you have started the IPython controller and one or more engines, you are ready to use the engines to do something useful. To make sure everything is working correctly, try the following commands:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]: &lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; IPython.parallel &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Client

In [&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]: c &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Client()

In [&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;]: c.ids
Out[&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;]: &lt;span class=&quot;bu&quot;&gt;set&lt;/span&gt;([&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;])

In [&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;]: c[:].apply_sync(&lt;span class=&quot;kw&quot;&gt;lambda&lt;/span&gt; : &lt;span class=&quot;st&quot;&gt;&amp;quot;Hello, World&amp;quot;&lt;/span&gt;)
Out[&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;]: [ &lt;span class=&quot;st&quot;&gt;&amp;#39;Hello, World&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;Hello, World&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;Hello, World&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;Hello, World&amp;#39;&lt;/span&gt; ]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;ipython-client-and-views&quot;&gt;IPython client and views&lt;/h2&gt;
&lt;p&gt;There is one primary object, the &lt;code&gt;Client&lt;/code&gt;, for connecting to a cluster. For each execution model, there is a corresponding &lt;code&gt;View&lt;/code&gt;. These views allow users to interact with a set of engines through the interface. Here are the two default views:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;DirectView&lt;/code&gt; class for explicit addressing.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;LoadBalancedView&lt;/code&gt; class for destination-agnostic scheduling.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]: &lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; IPython.parallel &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Client
In [&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]: rc &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Client()

&lt;span class=&quot;co&quot;&gt;# for a visible LAN controller listening on an external port:&lt;/span&gt;
In [&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]: rc &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Client(&lt;span class=&quot;st&quot;&gt;&amp;#39;tcp://192.168.1.16:10101&amp;#39;&lt;/span&gt;)
&lt;span class=&quot;co&quot;&gt;# or to connect with a specific profile you have set up:&lt;/span&gt;
In [&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;]: rc &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Client(profile&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;mpi&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;directview&quot;&gt;DirectView&lt;/h2&gt;
&lt;p&gt;For direct execution, we will make use of a &lt;code&gt;DirectView&lt;/code&gt; object, which can be constructed via list-access to the client:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;]: dview &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; rc[:] &lt;span class=&quot;co&quot;&gt;# use all engines&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;parallel-map&quot;&gt;Parallel map&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;62&lt;/span&gt;]: serial_result &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;lambda&lt;/span&gt; x:x&lt;span class=&quot;op&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;))

In [&lt;span class=&quot;dv&quot;&gt;63&lt;/span&gt;]: parallel_result &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; dview.map_sync(&lt;span class=&quot;kw&quot;&gt;lambda&lt;/span&gt; x: x&lt;span class=&quot;op&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;))

In [&lt;span class=&quot;dv&quot;&gt;67&lt;/span&gt;]: serial_result&lt;span class=&quot;op&quot;&gt;==&lt;/span&gt;parallel_result
Out[&lt;span class=&quot;dv&quot;&gt;67&lt;/span&gt;]: &lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;remote-function-decorators&quot;&gt;Remote function decorators&lt;/h3&gt;
&lt;p&gt;Remote functions are just like normal functions, but when they are called, they execute on one or more engines, rather than locally. IPython provides two decorators:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;]: @dview.remote(block&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;)
   ....: &lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; getpid():
   ....:     &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; os
   ....:     &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; os.getpid()
   ....:

In [&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;]: getpid()
Out[&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;]: [&lt;span class=&quot;dv&quot;&gt;12345&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;12346&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;12347&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;12348&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;@parallel&lt;/code&gt; decorator creates parallel functions, that break up an element-wise operations and distribute them, reconstructing the result.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt;]: &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np

In [&lt;span class=&quot;dv&quot;&gt;13&lt;/span&gt;]: A &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;48&lt;/span&gt;))

In [&lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;]: @dview.parallel(block&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;)
   ....: &lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; pmul(A,B):
   ....:     &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; A&lt;span class=&quot;op&quot;&gt;*&lt;/span&gt;B

In [&lt;span class=&quot;dv&quot;&gt;15&lt;/span&gt;]: C_local &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; A&lt;span class=&quot;op&quot;&gt;*&lt;/span&gt;A

In [&lt;span class=&quot;dv&quot;&gt;16&lt;/span&gt;]: C_remote &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; pmul(A,A)

In [&lt;span class=&quot;dv&quot;&gt;17&lt;/span&gt;]: (C_local &lt;span class=&quot;op&quot;&gt;==&lt;/span&gt; C_remote).&lt;span class=&quot;bu&quot;&gt;all&lt;/span&gt;()
Out[&lt;span class=&quot;dv&quot;&gt;17&lt;/span&gt;]: &lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A quick example to illustrate the difference in arguments for the two modes:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;16&lt;/span&gt;]: @dview.parallel(block&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;)
   ....: &lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; echo(x):
   ....:     &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;str&lt;/span&gt;(x)
   ....:

In [&lt;span class=&quot;dv&quot;&gt;17&lt;/span&gt;]: echo(&lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;))
Out[&lt;span class=&quot;dv&quot;&gt;17&lt;/span&gt;]: [&lt;span class=&quot;st&quot;&gt;&amp;#39;[0, 1]&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;[2]&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;[3]&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;[4]&amp;#39;&lt;/span&gt;]

In [&lt;span class=&quot;dv&quot;&gt;18&lt;/span&gt;]: echo.&lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;))
Out[&lt;span class=&quot;dv&quot;&gt;18&lt;/span&gt;]: [&lt;span class=&quot;st&quot;&gt;&amp;#39;0&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;2&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;3&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;4&amp;#39;&lt;/span&gt;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;calling-python-functions&quot;&gt;&lt;a href=&quot;http://ipython.org/ipython-doc/3/parallel/parallel_multiengine.html#calling-python-functions&quot;&gt;Calling Python functions&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The most basic type of operation that can be performed on the engines is to execute Python code or call Python functions. Executing Python code can be done in blocking or non-blocking mode (non-blocking is default) using the &lt;code&gt;View.execute()&lt;/code&gt; method, and calling functions can be done via the &lt;code&gt;View.apply()&lt;/code&gt; method.&lt;/p&gt;
&lt;h3 id=&quot;moving-python-objects-around&quot;&gt;&lt;a href=&quot;http://ipython.org/ipython-doc/3/parallel/parallel_multiengine.html#moving-python-objects-around&quot;&gt;Moving Python objects around&lt;/a&gt;&lt;/h3&gt;
&lt;h3 id=&quot;other-things-to-look-at&quot;&gt;&lt;a href=&quot;http://ipython.org/ipython-doc/3/parallel/parallel_multiengine.html#other-things-to-look-at&quot;&gt;Other things to look at&lt;/a&gt;&lt;/h3&gt;
&lt;h4 id=&quot;how-to-do-parallel-list-comprehensions&quot;&gt;How to do parallel list comprehensions&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;66&lt;/span&gt;]: dview.scatter(&lt;span class=&quot;st&quot;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;,&lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;))

In [&lt;span class=&quot;dv&quot;&gt;67&lt;/span&gt;]: &lt;span class=&quot;op&quot;&gt;%&lt;/span&gt;px y &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; [i&lt;span class=&quot;op&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; x]
Parallel execution on engines: [&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;]

In [&lt;span class=&quot;dv&quot;&gt;68&lt;/span&gt;]: y &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; dview.gather(&lt;span class=&quot;st&quot;&gt;&amp;#39;y&amp;#39;&lt;/span&gt;)

In [&lt;span class=&quot;dv&quot;&gt;69&lt;/span&gt;]: &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt; y
[&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1024&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;59049&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1048576&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;9765625&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;60466176&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;282475249&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1073741824&lt;/span&gt;,...]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&quot;remote-imports&quot;&gt;Remote imports&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;69&lt;/span&gt;]: &lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; dview.sync_imports():
   ....:     &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy
importing numpy on engine(s)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;sync_imports() does not allow import foo as bar syntax, because the assignment represented by the as bar part is not available to the import hook.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;parallel-exceptions&quot;&gt;&lt;a href=&quot;http://ipython.org/ipython-doc/3/parallel/parallel_multiengine.html#parallel-exceptions&quot;&gt;Parallel exceptions&lt;/a&gt;&lt;/h4&gt;
&lt;h2 id=&quot;loadbalancedview&quot;&gt;LoadBalancedView&lt;/h2&gt;
&lt;p&gt;For load-balanced execution, we will make use of a &lt;code&gt;LoadBalancedView&lt;/code&gt; object, which can be constructed via the client’s &lt;code&gt;load_balanced_view()&lt;/code&gt; method:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;]: lview &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; rc.load_balanced_view() &lt;span class=&quot;co&quot;&gt;# default load-balanced view&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;parallel-map-1&quot;&gt;Parallel map&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;62&lt;/span&gt;]: lview.block &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;

In [&lt;span class=&quot;dv&quot;&gt;63&lt;/span&gt;]: serial_result &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;lambda&lt;/span&gt; x:x&lt;span class=&quot;op&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;))

In [&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;]: parallel_result &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lview.&lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;lambda&lt;/span&gt; x:x&lt;span class=&quot;op&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;))

In [&lt;span class=&quot;dv&quot;&gt;65&lt;/span&gt;]: serial_result&lt;span class=&quot;op&quot;&gt;==&lt;/span&gt;parallel_result
Out[&lt;span class=&quot;dv&quot;&gt;65&lt;/span&gt;]: &lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;parallel-function-decorator&quot;&gt;Parallel function decorator&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;]: @lview.parallel()
   ....: &lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; f(x):
   ....:     &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;fl&quot;&gt;10.0&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;*&lt;/span&gt;x&lt;span class=&quot;op&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;
   ....:

In [&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;]: f.&lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;(&lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;))    &lt;span class=&quot;co&quot;&gt;# this is done in parallel&lt;/span&gt;
Out[&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;]: [&lt;span class=&quot;fl&quot;&gt;0.0&lt;/span&gt;,&lt;span class=&quot;fl&quot;&gt;10.0&lt;/span&gt;,&lt;span class=&quot;fl&quot;&gt;160.0&lt;/span&gt;,...]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;dependencies&quot;&gt;Dependencies&lt;/h3&gt;
&lt;h4 id=&quot;functional-dependencies&quot;&gt;Functional Dependencies&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;9&lt;/span&gt;]: &lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; IPython.parallel &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; depend, require, dependent
In [&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;]: @require(&lt;span class=&quot;st&quot;&gt;&amp;#39;numpy&amp;#39;&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;&amp;#39;zmq&amp;#39;&lt;/span&gt;)
   ....: &lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; myfunc():
   ....:     &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; dostuff()

In [&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;]: &lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; platform_specific(plat):
   ....:    &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; sys
   ....:    &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; sys.platform &lt;span class=&quot;op&quot;&gt;==&lt;/span&gt; plat

In [&lt;span class=&quot;dv&quot;&gt;11&lt;/span&gt;]: @depend(platform_specific, &lt;span class=&quot;st&quot;&gt;&amp;#39;darwin&amp;#39;&lt;/span&gt;)
   ....: &lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; mactask():
   ....:    do_mac_stuff()

In [&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt;]: @depend(platform_specific, &lt;span class=&quot;st&quot;&gt;&amp;#39;nt&amp;#39;&lt;/span&gt;)
   ....: &lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; wintask():
   ....:    do_windows_stuff()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&quot;graph-dependencies&quot;&gt;Graph Dependencies&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;In [&lt;span class=&quot;dv&quot;&gt;14&lt;/span&gt;]: client.block&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;False&lt;/span&gt;

In [&lt;span class=&quot;dv&quot;&gt;15&lt;/span&gt;]: ar &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lview.&lt;span class=&quot;bu&quot;&gt;apply&lt;/span&gt;(f, args, kwargs)

In [&lt;span class=&quot;dv&quot;&gt;16&lt;/span&gt;]: ar2 &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lview.&lt;span class=&quot;bu&quot;&gt;apply&lt;/span&gt;(f2)

In [&lt;span class=&quot;dv&quot;&gt;17&lt;/span&gt;]: &lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; lview.temp_flags(after&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[ar,ar2]):
   ....:    ar3 &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lview.&lt;span class=&quot;bu&quot;&gt;apply&lt;/span&gt;(f3)

In [&lt;span class=&quot;dv&quot;&gt;18&lt;/span&gt;]: &lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; lview.temp_flags(follow&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[ar], timeout&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;2.5&lt;/span&gt;)
   ....:    ar4 &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lview.&lt;span class=&quot;bu&quot;&gt;apply&lt;/span&gt;(f3)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
</description>
				<pubDate>Tue, 29 Dec 2015 00:00:00 +0800</pubDate>
				<link>/python/2015/12/29/ipython-parallel.html</link>
				<guid isPermaLink="true">/python/2015/12/29/ipython-parallel.html</guid>
			</item>
		
			<item>
				<title>python note</title>
				<description>&lt;h2 id=&quot;python-pip&quot;&gt;python pip&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;python pip&lt;/code&gt;的安装,&lt;a href=&quot;https://pip.pypa.io/en/latest/installing.html&quot; class=&quot;uri&quot;&gt;https://pip.pypa.io/en/latest/installing.html&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;升级pip：命令行下运行 python -m pip install -U pip&lt;/li&gt;
&lt;li&gt;用pip安装package：python -m pip install &lt;em&gt;package_name&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;package_name 在&lt;a href=&quot;https://pypi.python.org/pypi&quot; class=&quot;uri&quot;&gt;https://pypi.python.org/pypi&lt;/a&gt;搜索&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;module-search-path&quot;&gt;Module Search Path&lt;/h2&gt;
&lt;p&gt;When a module named spam is imported, the interpreter first searches for a built-in module with that name. If not found, it then searches for a file named spam.py in a list of directories given by the variable &lt;code&gt;sys.path&lt;/code&gt;. sys.path is initialized from these locations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the directory containing the input script (or the current directory).&lt;/li&gt;
&lt;li&gt;PYTHONPATH (a list of directory names, with the same syntax as the shell variable PATH).&lt;/li&gt;
&lt;li&gt;the installation-dependent default.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;dir&quot;&gt;dir()&lt;/h2&gt;
&lt;p&gt;he built-in function dir() is used to find out which names a module defines. It returns a sorted list of strings dir() does not list the names of built-in functions and variables. If you want a list of those, they are defined in the standard module &lt;code&gt;__builtin__&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; __builtin__
&lt;span class=&quot;bu&quot;&gt;dir&lt;/span&gt;(__builtin__)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;multiprocessing&quot;&gt;multiprocessing&lt;/h2&gt;
&lt;div class=&quot;sourceCode&quot;&gt;&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; multiprocessing &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Pool
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; multiprocessing.dummy &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Pool &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; ThreadPool
&lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;__name__&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;:
    pool &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; ThreadPool(&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;) &lt;span class=&quot;co&quot;&gt;# Sets the pool size to 4&lt;/span&gt;
    results&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;pool.&lt;span class=&quot;bu&quot;&gt;map&lt;/span&gt;(urllib2.urlopen, urls)
    pool.close()
    pool.join()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
</description>
				<pubDate>Mon, 28 Dec 2015 00:00:00 +0800</pubDate>
				<link>/python/2015/12/28/python-note.html</link>
				<guid isPermaLink="true">/python/2015/12/28/python-note.html</guid>
			</item>
		
			<item>
				<title>Maximum Entropy Model</title>
				<description>&lt;p&gt;&lt;a href=&quot;http://www.zhizhihu.com/html/y2011/3500.html&quot;&gt;原文链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;设随机变量&lt;span class=&quot;math inline&quot;&gt;\(\xi\)&lt;/span&gt;，他有&lt;span class=&quot;math inline&quot;&gt;\(A_1,A_2...A_n\)&lt;/span&gt;共&lt;span class=&quot;math inline&quot;&gt;\(n\)&lt;/span&gt;个不同的取值，每个取值出现的概率为&lt;span class=&quot;math inline&quot;&gt;\(p_1,p_2...p_n\)&lt;/span&gt;，那么&lt;span class=&quot;math inline&quot;&gt;\(\xi\)&lt;/span&gt;的不确定度，即信息熵为： &lt;span class=&quot;math display&quot;&gt;\[
H(\xi)=\sum_{i=1}^n p_i log_2{1 \over p_i}=-\sum_{i=1}^n p_i log_2 p_i
\]&lt;/span&gt; 熵越大，越不确定。熵为0，事件是确定的，例如抛硬币，每次事件发生的概率都是1/2的话，那么熵为1，即&lt;span class=&quot;math inline&quot;&gt;\(H(X)=-(0.5log_2 0.5+0.5log_2 0.5)=1\)&lt;/span&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;最大熵原理指出，当我们需要对一个随机事件的概率分布进行预测时，我们的预测应当满足全部已知的条件，而对未知的情况不要做任何主观假设。在这种情况下，概率分布最均匀，预测的风险最小。因为这时概率分布的信息熵最大，所以人们称这种模型叫“最大熵模型”。我们常说，不要把所有的鸡蛋放在一个篮子里，其实就是最大熵原理的一个朴素的说法，因为当我们遇到不确定性时，就要保留各种可能性。说白了，就是要保留全部的不确定性，将风险降到最小。—-摘自《Google黑板报》作者：吴军&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;自然语言处理的例子：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“学习”这个词可能是动词，也可能是名词。可以可以被标为主语、谓语、宾语、定语…… 令&lt;span class=&quot;math inline&quot;&gt;\(x_1\)&lt;/span&gt;表示“学习”被标为名词，&lt;span class=&quot;math inline&quot;&gt;\(x_2\)&lt;/span&gt;表示“学习”被标为动词。令&lt;span class=&quot;math inline&quot;&gt;\(y_1\)&lt;/span&gt;表示“学习”被标为主语，&lt;span class=&quot;math inline&quot;&gt;\(y_2\)&lt;/span&gt;表示被标为谓语，&lt;span class=&quot;math inline&quot;&gt;\(y_3\)&lt;/span&gt;表示宾语，&lt;span class=&quot;math inline&quot;&gt;\(y_4\)&lt;/span&gt;表示定语。得到下面的表示： &lt;span class=&quot;math display&quot;&gt;\[
p(x_1)+p(x_2)=1
\]&lt;/span&gt;&lt;span class=&quot;math display&quot;&gt;\[
\sum_{i=1}^4 p(y_i)=1
\]&lt;/span&gt; 如果没有其他的知识，根据信息熵的理论，概率趋向于均匀。所以有： &lt;span class=&quot;math display&quot;&gt;\[
p(x_1)=p(x_2)=0.5
\]&lt;/span&gt;&lt;span class=&quot;math display&quot;&gt;\[
p(y_1)=p(y_2)=p(y_3)=p(y_4)=0.25
\]&lt;/span&gt; 但是在实际情况中，“学习”被标为定语的可能性很小，只有0.05。我们引入这个新的知识：&lt;span class=&quot;math inline&quot;&gt;\(p(y_4)=0.05\)&lt;/span&gt;，在满足了这个约束的情况下，其他的事件我们尽可能的让他们符合自然，符合均匀分布： &lt;span class=&quot;math display&quot;&gt;\[
p(x_1)=p(x_2)=0.5
\]&lt;/span&gt;&lt;span class=&quot;math display&quot;&gt;\[
p(y_1)=p(y_2)=p(y_3)=0.953
\]&lt;/span&gt; 嗯，如果再加入一个知识，当“学习”被标作动词的时候，它被标作谓语的概率为0.95，这个其实是很自然的事情。都已经是动词了，那么是谓语的可能性就很大了： &lt;span class=&quot;math display&quot;&gt;\[
p(y_2|x_2)=0.95
\]&lt;/span&gt; 已经有了两个知识了，第二个还是条件概率的知识，那么其他的我们尽可能的让他们不受约束，不受影响，分布的均匀一些，现在应该怎么让他们符合尽可能的均匀分布呢？&lt;/p&gt;
&lt;p&gt;其实就是使熵尽可能的大就行了。也就是有个分布&lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;，他尽可能的把训练集中的知识表示出来，损失最小，并且还能够保证&lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;的熵最大： &lt;span class=&quot;math display&quot;&gt;\[
p^*=\mathop{argmax}\limits_p H(p)
\]&lt;/span&gt;&lt;/p&gt;
</description>
				<pubDate>Sun, 27 Dec 2015 00:00:00 +0800</pubDate>
				<link>/foundation/2015/12/27/maximum-entropy-model.html</link>
				<guid isPermaLink="true">/foundation/2015/12/27/maximum-entropy-model.html</guid>
			</item>
		
			<item>
				<title>LSTM A Search Space Odyssey</title>
				<description>&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;This paper reports the results of a large scale study on variations of the LSTM architecture.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The most commonly used LSTM architecture (vanilla LSTM) performs reasonably well on various datasets and using any of eight possible modifications does not significantly improve the LSTM performance.&lt;/li&gt;
&lt;li&gt;Certain modifications such as coupling the input and forget gates or removing peephole connections simplify LSTM without significantly hurting performance.&lt;/li&gt;
&lt;li&gt;The forget gate and the output activation function are the critical components of the LSTM block. While the first is crucial for LSTM performance, the second is necessary whenever the cell state is unbounded.&lt;/li&gt;
&lt;li&gt;Learning rate and network size are the most crucial tunable LSTM hyperparameters. Suerprisingly, the use of momentum was found to be unimportant (in setting of online gradient descent). Gaussian noise on the inputs was found to be moderately helpful for TIMIT, but harmful for other datasets.&lt;/li&gt;
&lt;li&gt;The analysis of hyperparameter interactions revealed that even the highest measured interaction (between learning rate and network size) is quite small. This implies that the hyperparameters can be tuned independently. In particular, the learning rate can be calibrated first using a fairly small network, thus saving a lot of experimentation time.&lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Thu, 24 Dec 2015 00:00:00 +0800</pubDate>
				<link>/foundation/paper/2015/12/24/lstm-a-search-space-odyssey.html</link>
				<guid isPermaLink="true">/foundation/paper/2015/12/24/lstm-a-search-space-odyssey.html</guid>
			</item>
		
			<item>
				<title>Sentiment analysis</title>
				<description>&lt;p&gt;Sentiment analysis has many other names&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Opinion extraction&lt;/li&gt;
&lt;li&gt;Opinion mining&lt;/li&gt;
&lt;li&gt;Sentiment mining&lt;/li&gt;
&lt;li&gt;Subjectively analysis&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;learning-sentiment-lexicons&quot;&gt;Learning Sentiment Lexicons&lt;/h2&gt;
&lt;h3 id=&quot;pointwise-mutual-information&quot;&gt;Pointwise Mutual Information&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mutual information&lt;/strong&gt; between 2 random variables &lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(Y\)&lt;/span&gt; &lt;span class=&quot;math display&quot;&gt;\[
I(X,Y)=\sum_x \sum_y P(x,y)log_2 \frac{P(x,y)}{P(x)P(y)}
\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pointwise mutual information&lt;/strong&gt;: How much more do events &lt;span class=&quot;math inline&quot;&gt;\(x\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(y\)&lt;/span&gt; co-occur than if they were independent? &lt;span class=&quot;math display&quot;&gt;\[
PMI(X,Y)=log_2 \frac{P(x,y)}{P(x)P(y)}
\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PMI between two words&lt;/strong&gt;: &lt;span class=&quot;math display&quot;&gt;\[
PMI(word_1, word_2)=log_2 \frac{P(word_1, word_2)}{P(word_1)P(word_2)}
\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;how-to-estimate-pointwise-mutual-information&quot;&gt;How to Estimate Pointwise Mutual Information&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Query search engine (Altavista)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&quot;math inline&quot;&gt;\(P(word)\)&lt;/span&gt; estimated by &lt;span class=&quot;math inline&quot;&gt;\(hits(word)/N\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&quot;math inline&quot;&gt;\(P(word_1, word_2)\)&lt;/span&gt; by &lt;span class=&quot;math inline&quot;&gt;\(hits(word_1 \text{ NEAR } word_2)/N^2\)&lt;/span&gt; &lt;span class=&quot;math display&quot;&gt;\[
PMI(word_1, word_2)=log_2 \frac{hits(word_1\text{ NEAR } word_2)}{hits(word_1)hits(word_2)}
\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Does phrase appear more with “poor” or “excellent” &lt;span class=&quot;math display&quot;&gt;\[
\begin{align}
Polarity(phrase)&amp;amp;=PMI(phrase, \text{&amp;quot;excellent&amp;quot;})-PMI(phrase, \text{&amp;quot;poor&amp;quot;})\\
&amp;amp;=log_2 \frac{hits(phrase \text{ NEAR &amp;quot;excellent&amp;quot;})}{hits(phrase)hits(\text{&amp;quot;excellent&amp;quot;})} - log_2 \frac{hits(phrase \text{ NEAR &amp;quot;poor&amp;quot;})}{hits(phrase)hits(\text{&amp;quot;poor&amp;quot;})} \\
&amp;amp;=log_2 \frac{hits(phrase \text{ NEAR &amp;quot;excellent&amp;quot;})}{hits(phrase)hits(\text{&amp;quot;excellent&amp;quot;})} \frac{hits(phrase \text{ NEAR &amp;quot;poor&amp;quot;})}{hits(phrase)hits(\text{&amp;quot;poor&amp;quot;})} \\
&amp;amp;=log_2\left( \frac{hits(phrase \text{ NEAR &amp;quot;excellent&amp;quot;})hits(\text{&amp;quot;poor&amp;quot;})}{hits(phrase \text{ NEAR &amp;quot;poor&amp;quot;})hits(\text{&amp;quot;excellent&amp;quot;})} \right)
\end{align}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;other-sentiment-tasks&quot;&gt;Other Sentiment Tasks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Finding sentiment of a sentence
&lt;ul&gt;
&lt;li&gt;The food was great but the service was awful.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Finding aspect/attribute/target of sentiment&lt;/li&gt;
&lt;li&gt;Detection of Friendliness&lt;/li&gt;
&lt;/ul&gt;
</description>
				<pubDate>Wed, 23 Dec 2015 00:00:00 +0800</pubDate>
				<link>/foundation/nlp/2015/12/23/sentiment-analysis.html</link>
				<guid isPermaLink="true">/foundation/nlp/2015/12/23/sentiment-analysis.html</guid>
			</item>
		
			<item>
				<title>Improving Word Representations via Global Context and Multiple Word Prototypes</title>
				<description>&lt;h2 id=&quot;global-context-aware-neural-language-model&quot;&gt;Global Context-Aware Neural Language Model&lt;/h2&gt;
&lt;h3 id=&quot;training-objective&quot;&gt;Training Objective&lt;/h3&gt;
&lt;p&gt;Given a word sequence &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt; and document &lt;span class=&quot;math inline&quot;&gt;\(d\)&lt;/span&gt; in which the sequence occurs, our goal is to discriminate the correct last word in &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt; from other random words. We compute scores &lt;span class=&quot;math inline&quot;&gt;\(g(s,d)\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(g(s^w,d)\)&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(s^w\)&lt;/span&gt; is &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt; with the last word replaced by word &lt;span class=&quot;math inline&quot;&gt;\(w\)&lt;/span&gt;, and &lt;span class=&quot;math inline&quot;&gt;\(g(·,·)\)&lt;/span&gt; is the scoring function that represents the neural networks used. We want &lt;span class=&quot;math inline&quot;&gt;\(g(s,d)\)&lt;/span&gt; to be larger than &lt;span class=&quot;math inline&quot;&gt;\(g(s^w,d)\)&lt;/span&gt; by a margin of 1, for any other word &lt;span class=&quot;math inline&quot;&gt;\(w\)&lt;/span&gt; in the vocabulary, which corresponds to the training objective of minimizing the ranking loss for each &lt;span class=&quot;math inline&quot;&gt;\((s,d)\)&lt;/span&gt; found in the corpus: &lt;span class=&quot;math display&quot;&gt;\[
C_{s,d}=\sum_{w\in V} max(0, 1-g(s,d)+g(s^w,d))
\]&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;neural-network-architecture&quot;&gt;Neural Network Architecture&lt;/h3&gt;
&lt;figure&gt;
&lt;img src=&quot;/assets/images/27.png&quot; alt=&quot;An overview of the neural language model. The model makes use of both local and global context to compute a score that should be large for the actual next word (bank in the example), compare to the score for other words. When word meaning is still ambiguous given local context, information in global context can help disambiguation.&quot; /&gt;&lt;figcaption&gt;An overview of the neural language model. The model makes use of both local and global context to compute a score that should be large for the actual next word (bank in the example), compare to the score for other words. When word meaning is still ambiguous given local context, information in global context can help disambiguation.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;The score of local context uses the local word sequence &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt;. We first represent the word sequence &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt; as an ordered list of vectors &lt;span class=&quot;math inline&quot;&gt;\(x=(x_1,x_2,...,x_m)\)&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(x_i\)&lt;/span&gt; is the embedding of word &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; in the sequence, which is a column in the embedding matrix &lt;span class=&quot;math inline&quot;&gt;\(L\in \Bbb R^{n\times |V|}\)&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(|V|\)&lt;/span&gt; denotes the size of the vocabulary. &lt;strong&gt;The columns of this embedding matrix &lt;span class=&quot;math inline&quot;&gt;\(L\)&lt;/span&gt; are the word vectors and will be learned and updated during training.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To compute the score of local context, &lt;span class=&quot;math inline&quot;&gt;\(socre_l\)&lt;/span&gt;, use a neural network with one hidden layer: &lt;span class=&quot;math display&quot;&gt;\[
a_1=f(W_1[x_1;x_2;...;x_m]+b_1)
\]&lt;/span&gt; &lt;span class=&quot;math display&quot;&gt;\[
score_l=W_2a_1+b_2
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\([x_1;x_2;...;x_m]\)&lt;/span&gt; is the concatenation of the &lt;span class=&quot;math inline&quot;&gt;\(m\)&lt;/span&gt; word embeddings representing sequence &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(f\)&lt;/span&gt; is an element-wise activation function such as &lt;span class=&quot;math inline&quot;&gt;\(tanh\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(a_1\in \Bbb R^{h\times 1}\)&lt;/span&gt; is the activation of the hidden layer with &lt;span class=&quot;math inline&quot;&gt;\(h\)&lt;/span&gt; hidden nodes, &lt;span class=&quot;math inline&quot;&gt;\(W_1\in \Bbb R^{h\times \\(mn\\)}\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(W_2\in\Bbb R^{1\times h}\)&lt;/span&gt; are respectively the first and second layer weights of the neural network, and &lt;span class=&quot;math inline&quot;&gt;\(b_1\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(b_2\)&lt;/span&gt; are the biases of each layer.&lt;/p&gt;
&lt;p&gt;For the score of the global context, we represent the document also as an ordered list of word embedding, &lt;span class=&quot;math inline&quot;&gt;\(d=(d_1,d_2,...,d_k)\)&lt;/span&gt;. First compute the weighted average of all word vectors in the document: &lt;span class=&quot;math display&quot;&gt;\[
c=\frac{\sum_{i=1}^k w(t_i)d_i}{\sum_{i=1}^k w(t_i)}
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(w(·)\)&lt;/span&gt; can be any weighting function that captures the importance of word &lt;span class=&quot;math inline&quot;&gt;\(t_i\)&lt;/span&gt; in the document. We use idf-weighting as the weighting function. Use a two-layer neural network to compute the global context score, &lt;span class=&quot;math inline&quot;&gt;\(score_g\)&lt;/span&gt;, similar to the above: &lt;span class=&quot;math display&quot;&gt;\[
a_1^g=f(W_1^g[c;x_m]+b_1^g)
\]&lt;/span&gt; &lt;span class=&quot;math display&quot;&gt;\[
score_g=W_2^ga_1^g+b_2^g
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\([c;x_m]\)&lt;/span&gt; is the concatenation of the weighted average document vector and the vector of the last word in &lt;span class=&quot;math inline&quot;&gt;\(s\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note that instead of using the document where the sequence occurs, we can also specify a fixed &lt;span class=&quot;math inline&quot;&gt;\(k&amp;gt;m\)&lt;/span&gt; that captures larger context.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The final score is the sum of the two scores: &lt;span class=&quot;math display&quot;&gt;\[
score = score_l+score_g
\]&lt;/span&gt; The local score preserves word order and syntactic information, while the global score uses a weighted average which is similar to bag-of-words features, capturing more of the semantics and topics of the document.&lt;/p&gt;
&lt;h3 id=&quot;learning&quot;&gt;Learning&lt;/h3&gt;
&lt;p&gt;Word embeddings move to good positions in the vector space faster when using &lt;code&gt;mini-batch L-BFGS&lt;/code&gt; (Liu and Nocedal, 1989) with 1000 pairs of good and corrupt examples per batch for training, compared to stochastic gradient descent.&lt;/p&gt;
&lt;h2 id=&quot;multi-prototype-neural-language-model&quot;&gt;Multi-Prototype Neural Language Model&lt;/h2&gt;
&lt;p&gt;In order to learn multiple prototypes, we first gather the fixed-sized context windows of all occurrences of a word (we use 5 words before and after the word occurrence). Each context is represented by a weighted average of the context words’ vectors, where again, we use &lt;code&gt;idf-weighting&lt;/code&gt; as the weighting function. Then use &lt;code&gt;spherical k-means&lt;/code&gt; to cluster these context representations. Finally, each word occurrence in the corpus is re-labeled to its associated cluster and is used to train the word representation for that cluster.&lt;/p&gt;
&lt;p&gt;Similarity between a pair of words &lt;span class=&quot;math inline&quot;&gt;\((w, w&amp;#39;)\)&lt;/span&gt; using the multi-prototype approach can be computed with of without context, as defined by Reisinger and Mooney (2010b): &lt;span class=&quot;math display&quot;&gt;\[
AvgSimC(w,w&amp;#39;)={1 \over K^2}\sum_{i=1}^k \sum_{j=1}^k p(c,w,i)p(c&amp;#39;,w&amp;#39;,j)d(\mu_i(w), \mu_j(w&amp;#39;))
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(p(c,w,i)\)&lt;/span&gt; is the likelihood that word &lt;span class=&quot;math inline&quot;&gt;\(w\)&lt;/span&gt; is in its cluser &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt; given context &lt;span class=&quot;math inline&quot;&gt;\(c\)&lt;/span&gt;, &lt;span class=&quot;math inline&quot;&gt;\(\mu_i(w)\)&lt;/span&gt; is the vector representing the &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;-th cluster centroid of &lt;span class=&quot;math inline&quot;&gt;\(w\)&lt;/span&gt;, and &lt;span class=&quot;math inline&quot;&gt;\(d(v,v&amp;#39;)\)&lt;/span&gt; is a function computing similarity between two vectors, which can be any of the distance functions presented by Curran(2004). The similarity measure can be computed in absence of context by assuming uniform &lt;span class=&quot;math inline&quot;&gt;\(p(c,w,i)\)&lt;/span&gt; over &lt;span class=&quot;math inline&quot;&gt;\(i\)&lt;/span&gt;.&lt;/p&gt;
</description>
				<pubDate>Wed, 23 Dec 2015 00:00:00 +0800</pubDate>
				<link>/foundation/paper/2015/12/23/improving-word-representations-via-global-context-and-multiple-word-prototypes.html</link>
				<guid isPermaLink="true">/foundation/paper/2015/12/23/improving-word-representations-via-global-context-and-multiple-word-prototypes.html</guid>
			</item>
		
			<item>
				<title>Neural Reasoner</title>
				<description>&lt;h2 id=&quot;overview-of-neural-reasoner&quot;&gt;Overview of Neural Reasoner&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Neural Reasoner&lt;/strong&gt; has a layered architecture to deal with the complicated logical relations in reasoning as illustrated in Figure 1:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/assets/images/24.png&quot; alt=&quot;&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;It consists of &lt;code&gt;one encoding layer&lt;/code&gt; and &lt;code&gt;multiple reasoning layers&lt;/code&gt;. The encoder layers first converts the question and facts from natural language sentences to vectorial representations. More specifically, &lt;span class=&quot;math display&quot;&gt;\[
Q \quad \underrightarrow{encode} \quad q^{(0)} , F_k \quad \underrightarrow{encode} \quad f_k^{(0)},k=1,2,...,K.
\]&lt;/span&gt; where &lt;span class=&quot;math inline&quot;&gt;\(q^{(0)} \in \Bbb R^{d_Q}\)&lt;/span&gt; and &lt;span class=&quot;math inline&quot;&gt;\(f_k^{(0)} \in \Bbb R^{d_F}\)&lt;/span&gt;. With the representations obtained from the encoding layer, the reasoning layer recursively updates the representations of questions and facts, &lt;span class=&quot;math display&quot;&gt;\[
\{q^{(l)}f_1^{(l)}\dotsb f_K^{(l)}\}\quad \underrightarrow{reason} \quad\{q^{(l+1)}f_1^{(l+1)}\dotsb f_K^{(l+1)}\}
\]&lt;/span&gt; through the interaction between question representation and fact representations. Intuitively, this interaction models the reasoning, including examination of the facts and comparison of the facts and the questions. Finally at layer-&lt;span class=&quot;math inline&quot;&gt;\(L\)&lt;/span&gt;, the resulted question representation &lt;span class=&quot;math inline&quot;&gt;\(q^{(L)}\)&lt;/span&gt; is fed to an answerer, which layer can be a classifier for choosing between a number of pre-determined classes (e.g., {Yes, No}) or a text generator for create a sentence.&lt;/p&gt;
&lt;p&gt;Neural Reasoner has the following desired properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it can handle varying number of facts, including irrelevant ones, and reach the final conclusion through repeated processing of filtering and combining;&lt;/li&gt;
&lt;li&gt;it makes no assumption about the form of language, as long as enough training examples are given.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;model&quot;&gt;Model&lt;/h2&gt;
&lt;figure&gt;
&lt;img src=&quot;/assets/images/25.png&quot; alt=&quot;A diagram of implementation of Neural Reasoner with L reasoning layers, operating on one question and K facts&quot; /&gt;&lt;figcaption&gt;A diagram of implementation of Neural Reasoner with L reasoning layers, operating on one question and K facts&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;auxiliary-training-for-questionfact-representation&quot;&gt;Auxiliary Training for Question/Fact Representation&lt;/h2&gt;
&lt;p&gt;Use auxiliary training to facilitate the learning of representations of question and facts. Basically, in addition to using the learned representations of question and facts in the reasoning process, also use those representations to reconstruct the original questions or their more abstract forms with variables.&lt;/p&gt;
&lt;p&gt;In the auxiliary training, intend to achieve the following two goals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;to compensate the lack of supervision in the learning task. In experiments, the supervision can be fairly weak since for each instance it is merely a classification with no more than 12 classes, while the number of instances are 1K to 10K.&lt;/li&gt;
&lt;li&gt;to introduce beneficial bias for the representation learning task. Since the network is a complicated nonlinear function, the back-propagation from the answering layer to the encoding layer can easily fail to learn well.&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
&lt;img src=&quot;/assets/images/26.png&quot; alt=&quot;Auxiliary training for question representation. The training for fact representation is identical and therefore omitted&quot; /&gt;&lt;figcaption&gt;Auxiliary training for question representation. The training for fact representation is identical and therefore omitted&lt;/figcaption&gt;
&lt;/figure&gt;
</description>
				<pubDate>Mon, 21 Dec 2015 00:00:00 +0800</pubDate>
				<link>/foundation/paper/2015/12/21/neural-reasoner.html</link>
				<guid isPermaLink="true">/foundation/paper/2015/12/21/neural-reasoner.html</guid>
			</item>
		
			<item>
				<title>OXFORD Machine Learning</title>
				<description>&lt;p&gt;&lt;a href=&quot;https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/&quot;&gt;Course Page&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;lecture-2-linear-supervised-learning&quot;&gt;Lecture 2 Linear supervised learning&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Many real processes can be &lt;em&gt;approximated&lt;/em&gt; with linear models.&lt;/li&gt;
&lt;li&gt;Linear regression often appears as a &lt;em&gt;module&lt;/em&gt; of larger systems.&lt;/li&gt;
&lt;li&gt;Linear problems can be solved &lt;em&gt;analytically&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Linear prediction provides an introduction to many of the &lt;em&gt;core concepts&lt;/em&gt; of machine learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
&lt;img src=&quot;/assets/images/19.png&quot; alt=&quot;&quot; /&gt;
&lt;/figure&gt;
&lt;h2 id=&quot;lecture-3&quot;&gt;Lecture 3&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/20.png&quot; alt=&quot;&quot; /&gt; &lt;img src=&quot;/assets/images/21.png&quot; alt=&quot;&quot; /&gt; &lt;img src=&quot;/assets/images/22.png&quot; alt=&quot;&quot; /&gt; &lt;img src=&quot;/assets/images/23.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
				<pubDate>Sat, 19 Dec 2015 00:00:00 +0800</pubDate>
				<link>/foundation/2015/12/19/oxford-machine-learning.html</link>
				<guid isPermaLink="true">/foundation/2015/12/19/oxford-machine-learning.html</guid>
			</item>
		
			<item>
				<title>How to Choose a Neural Network</title>
				<description>&lt;figure&gt;
&lt;img src=&quot;/assets/images/18.png&quot; alt=&quot;&quot; /&gt;
&lt;/figure&gt;
</description>
				<pubDate>Sat, 19 Dec 2015 00:00:00 +0800</pubDate>
				<link>/method/2015/12/19/how-to-choose-a-neural-network.html</link>
				<guid isPermaLink="true">/method/2015/12/19/how-to-choose-a-neural-network.html</guid>
			</item>
		
			<item>
				<title>Basic conception</title>
				<description>&lt;h2 id=&quot;standard-deviation&quot;&gt;Standard Deviation&lt;/h2&gt;
&lt;p&gt;In statistics and probability theory, the standard deviation (SD) (represented by the Greek letter sigma, &lt;span class=&quot;math inline&quot;&gt;\(\sigma\)&lt;/span&gt;) measures the amount of variation or dispersion from the average. A low standard deviation indicates that the data points tend to be very close to the mean (also called expected value); a high standard deviation indicates that the data points are spread out over a large range of values.&lt;/p&gt;
&lt;h2 id=&quot;derivative&quot;&gt;Derivative&lt;/h2&gt;
&lt;p&gt;The derivative of a function of a real variable measures the sensitivity to change of a quantity (a function or dependent variable) which is determined by another quantity (the independent variable). For example, the derivative of the position of a moving object with respect to time is the object’s velocity: this measures how quickly the position of the object changes when time is advanced.当x变化时，y的变化量。&lt;/p&gt;
</description>
				<pubDate>Sat, 19 Dec 2015 00:00:00 +0800</pubDate>
				<link>/foundation/2015/12/19/basic-conception.html</link>
				<guid isPermaLink="true">/foundation/2015/12/19/basic-conception.html</guid>
			</item>
		
	</channel>
</rss>

<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Torch7 doc | An old brother's memo.</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/very-simple.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"></head><body><!-- include the sidebar--><!-- include ./includes/sidebar.jade--><!-- Blog title and subtitle--><header><div class="container header"><a id="logo" href="/." class="title">An old brother's memo.</a><span class="subtitle"></span><label id="toggle-menu" for="menu" onclick><i class="fa fa-bars"></i></label></div></header><!-- use checkbox hack for toggle nav-bar on small screens--><input id="menu" type="checkbox"><!-- Navigation Links--><nav id="nav"><div class="container"><a href="/" class="sidebar-nav-item active">Home</a><a href="/archives" class="sidebar-nav-item">Archives</a></div></nav><div id="header-margin-bar"></div><!-- gallery that comes before the header--><div class="wrapper"><div class="container post-header"><h1>Torch7 doc</h1></div></div><div class="wrapper"><div class="container meta"><div class="post-time">2016-07-14</div><div class="post-categories"><a class="post-category-link" href="/categories/machine-learning/">machine learning</a></div><div class="post-tags"><a class="post-tag-link" href="/tags/lua/">lua</a>/<a class="post-tag-link" href="/tags/torch/">torch</a></div></div></div><article><div class="container post"><h2 id="torch"><a href="#torch" class="headerlink" title="torch"></a>torch</h2><h3 id="res-torch-clamp-res-tensor1-min-value-max-value"><a href="#res-torch-clamp-res-tensor1-min-value-max-value" class="headerlink" title="[res] torch.clamp([res,] tensor1, min_value, max_value)"></a>[res] torch.clamp([res,] tensor1, min_value, max_value)</h3><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">--[[</span></div><div class="line">Clamp all elements in the tensor into the range [min_value, max_value].</div><div class="line">ie:</div><div class="line">y_i = x_i,  if x_i &gt;= min_value or x_i &lt;= max_value</div><div class="line">    y_i = min_value,  if x_i &lt; min_value</div><div class="line">    y_i = max_value,  if x_i &gt; max_value </div><div class="line"></div><div class="line"></div><div class="line">z=torch.clamp(x,0,1) will return a new tensor </div><div class="line">with the result of x bounded between 0 and 1.</div><div class="line"></div><div class="line"></div><div class="line">torch.clamp(z,x,0,1) will put the result in z .</div><div class="line"></div><div class="line"></div><div class="line">x:clamp(0,1) will perform the clamp operation in place</div><div class="line">(putting the result in x ).</div><div class="line"></div><div class="line"></div><div class="line"> z:clamp(x,0,1) will put the result in z .</div><div class="line"> ]]</div></pre></td></tr></table></figure>
<h2 id="nn"><a href="#nn" class="headerlink" title="nn"></a>nn</h2><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">nn.SplitTable()    <span class="comment">-- (N)dim Tensor -&gt; table of (N-1)dim Tensors</span></div><div class="line">nn.JoinTable()    <span class="comment">-- table of (N-1)dim Tensors -&gt; (N)dim Tensor</span></div><div class="line"><span class="comment">--[[</span></div><div class="line">This function returns noutput number of new nodes </div><div class="line">that each take a single component of the output of this </div><div class="line">node in the order they are returned.</div><div class="line">]]</div><div class="line">nngraph.Node:split(noutput)</div></pre></td></tr></table></figure>
<h2 id="torch-Tensor"><a href="#torch-Tensor" class="headerlink" title="torch.Tensor"></a>torch.Tensor</h2><h3 id="result-view-result-tensor-sizes"><a href="#result-view-result-tensor-sizes" class="headerlink" title="[result] view([result,] tensor, sizes)"></a>[result] view([result,] tensor, sizes)</h3><p>Creates a view with different dimensions of the storage associated with <code>tensor</code>.<br>If <code>result</code> is not passed, then a new tensor is returned, otherwise its storage is<br>made to point to storage of <code>tensor</code>.</p>
<p><code>sizes</code> can either be a <code>torch.LongStorage</code> or numbers. If one of the dimensions<br>is -1, the size of that dimension is inferred from the rest of the elements.</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">x = torch.zeros(<span class="number">4</span>)</div><div class="line">&gt; x:view(<span class="number">2</span>,<span class="number">2</span>)</div><div class="line"> <span class="number">0</span> <span class="number">0</span></div><div class="line"> <span class="number">0</span> <span class="number">0</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">2</span>x2]</div><div class="line"></div><div class="line"></div><div class="line">&gt; x:view(<span class="number">2</span>,<span class="number">-1</span>)</div><div class="line"> <span class="number">0</span> <span class="number">0</span></div><div class="line"> <span class="number">0</span> <span class="number">0</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">2</span>x2]</div><div class="line"></div><div class="line"></div><div class="line">&gt; x:view(torch.LongStorage&#123;<span class="number">2</span>,<span class="number">2</span>&#125;)</div><div class="line"> <span class="number">0</span> <span class="number">0</span></div><div class="line"> <span class="number">0</span> <span class="number">0</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">2</span>x2]</div><div class="line"></div><div class="line"></div><div class="line">&gt; x</div><div class="line"> <span class="number">0</span></div><div class="line"> <span class="number">0</span></div><div class="line"> <span class="number">0</span></div><div class="line"> <span class="number">0</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">4</span>]</div></pre></td></tr></table></figure>
<h3 id="result-split-result-tensor-size-dim"><a href="#result-split-result-tensor-size-dim" class="headerlink" title="[result] split([result,] tensor, size, [dim])"></a>[result] split([result,] tensor, size, [dim])</h3><p>Splits Tensor <code>tensor</code> along dimension <code>dim</code><br>into a <code>result</code> table of Tensors of size <code>size</code> (a number)<br>or less (in the case of the last Tensor). The sizes of the non-<code>dim</code><br>dimensions remain unchanged. Internally, a series of<br><a href="#torch.Tensor.narrow">narrows</a> are performed along<br>dimensions <code>dim</code>. Argument <code>dim</code> defaults to 1.</p>
<p>If <code>result</code> is not passed, then a new table is returned, otherwise it<br>is emptied and reused. </p>
<p>Example:<br><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">x = torch.randn(<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</div><div class="line"></div><div class="line"></div><div class="line">&gt; x:split(<span class="number">2</span>,<span class="number">1</span>)</div><div class="line">&#123;</div><div class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">2</span>x4x5</div><div class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">1</span>x4x5</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">&gt; x:split(<span class="number">3</span>,<span class="number">2</span>)</div><div class="line">&#123;</div><div class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">3</span>x3x5</div><div class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">3</span>x1x5</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line">&gt; x:split(<span class="number">2</span>,<span class="number">3</span>)</div><div class="line">&#123;</div><div class="line">  <span class="number">1</span> : DoubleTensor - size: <span class="number">3</span>x4x2</div><div class="line">  <span class="number">2</span> : DoubleTensor - size: <span class="number">3</span>x4x2</div><div class="line">  <span class="number">3</span> : DoubleTensor - size: <span class="number">3</span>x4x1</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="Tensor-index-dim-index"><a href="#Tensor-index-dim-index" class="headerlink" title="[Tensor] index(dim, index)"></a>[Tensor] index(dim, index)</h3><p>Returns a new <code>Tensor</code> which indexes the original <code>Tensor</code> along dimension <code>dim</code><br>using the entries in <code>torch.LongTensor</code> <code>index</code>.<br>The returned <code>Tensor</code> has the same number of dimensions as the original <code>Tensor</code>.<br>The returned <code>Tensor</code> does <strong>not</strong> use the same storage as the original <code>Tensor</code> – see below for storing the result<br> in an existing <code>Tensor</code>.</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">x = torch.rand(<span class="number">5</span>,<span class="number">5</span>)</div><div class="line">&gt; x</div><div class="line"> <span class="number">0.8020</span>  <span class="number">0.7246</span>  <span class="number">0.1204</span>  <span class="number">0.3419</span>  <span class="number">0.4385</span></div><div class="line"> <span class="number">0.0369</span>  <span class="number">0.4158</span>  <span class="number">0.0985</span>  <span class="number">0.3024</span>  <span class="number">0.8186</span></div><div class="line"> <span class="number">0.2746</span>  <span class="number">0.9362</span>  <span class="number">0.2546</span>  <span class="number">0.8586</span>  <span class="number">0.6674</span></div><div class="line"> <span class="number">0.7473</span>  <span class="number">0.9028</span>  <span class="number">0.1046</span>  <span class="number">0.9085</span>  <span class="number">0.6622</span></div><div class="line"> <span class="number">0.1412</span>  <span class="number">0.6784</span>  <span class="number">0.1624</span>  <span class="number">0.8113</span>  <span class="number">0.3949</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">5</span>x5]</div><div class="line"></div><div class="line"></div><div class="line">y = x:index(<span class="number">1</span>,torch.LongTensor&#123;<span class="number">3</span>,<span class="number">1</span>&#125;)</div><div class="line">&gt; y</div><div class="line"> <span class="number">0.2746</span>  <span class="number">0.9362</span>  <span class="number">0.2546</span>  <span class="number">0.8586</span>  <span class="number">0.6674</span></div><div class="line"> <span class="number">0.8020</span>  <span class="number">0.7246</span>  <span class="number">0.1204</span>  <span class="number">0.3419</span>  <span class="number">0.4385</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">2</span>x5]</div><div class="line"></div><div class="line"></div><div class="line">y:fill(<span class="number">1</span>)</div><div class="line">&gt; y</div><div class="line"> <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span></div><div class="line"> <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span>  <span class="number">1</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">2</span>x5]</div><div class="line"></div><div class="line"></div><div class="line">&gt; x</div><div class="line"> <span class="number">0.8020</span>  <span class="number">0.7246</span>  <span class="number">0.1204</span>  <span class="number">0.3419</span>  <span class="number">0.4385</span></div><div class="line"> <span class="number">0.0369</span>  <span class="number">0.4158</span>  <span class="number">0.0985</span>  <span class="number">0.3024</span>  <span class="number">0.8186</span></div><div class="line"> <span class="number">0.2746</span>  <span class="number">0.9362</span>  <span class="number">0.2546</span>  <span class="number">0.8586</span>  <span class="number">0.6674</span></div><div class="line"> <span class="number">0.7473</span>  <span class="number">0.9028</span>  <span class="number">0.1046</span>  <span class="number">0.9085</span>  <span class="number">0.6622</span></div><div class="line"> <span class="number">0.1412</span>  <span class="number">0.6784</span>  <span class="number">0.1624</span>  <span class="number">0.8113</span>  <span class="number">0.3949</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">5</span>x5]</div></pre></td></tr></table></figure>
<p>Note the explicit <code>index</code> function is different than the indexing operator <code>[]</code>.<br>The indexing operator <code>[]</code> is a syntactic shortcut for a series of select and narrow operations,<br>therefore it always returns a new view on the original tensor that shares the same storage.<br>However, the explicit <code>index</code> function can not use the same storage.</p>
<p>It is possible to store the result into an existing Tensor with <code>result:index(source, ...)</code>:</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">x = torch.rand(<span class="number">5</span>,<span class="number">5</span>)</div><div class="line">&gt; x</div><div class="line"> <span class="number">0.8020</span>  <span class="number">0.7246</span>  <span class="number">0.1204</span>  <span class="number">0.3419</span>  <span class="number">0.4385</span></div><div class="line"> <span class="number">0.0369</span>  <span class="number">0.4158</span>  <span class="number">0.0985</span>  <span class="number">0.3024</span>  <span class="number">0.8186</span></div><div class="line"> <span class="number">0.2746</span>  <span class="number">0.9362</span>  <span class="number">0.2546</span>  <span class="number">0.8586</span>  <span class="number">0.6674</span></div><div class="line"> <span class="number">0.7473</span>  <span class="number">0.9028</span>  <span class="number">0.1046</span>  <span class="number">0.9085</span>  <span class="number">0.6622</span></div><div class="line"> <span class="number">0.1412</span>  <span class="number">0.6784</span>  <span class="number">0.1624</span>  <span class="number">0.8113</span>  <span class="number">0.3949</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">5</span>x5]</div><div class="line"></div><div class="line"></div><div class="line">y = torch.Tensor()</div><div class="line">y:index(x,<span class="number">1</span>,torch.LongTensor&#123;<span class="number">3</span>,<span class="number">1</span>&#125;)</div><div class="line">&gt; y</div><div class="line"> <span class="number">0.2746</span>  <span class="number">0.9362</span>  <span class="number">0.2546</span>  <span class="number">0.8586</span>  <span class="number">0.6674</span></div><div class="line"> <span class="number">0.8020</span>  <span class="number">0.7246</span>  <span class="number">0.1204</span>  <span class="number">0.3419</span>  <span class="number">0.4385</span></div><div class="line">[torch.DoubleTensor of dimension <span class="number">2</span>x5]</div></pre></td></tr></table></figure>
<h2 id="nn-Module"><a href="#nn-Module" class="headerlink" title="nn.Module"></a>nn.Module</h2><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">:training()</div><div class="line"><span class="comment">--[[</span></div><div class="line">This sets the mode of the Module (or sub-modules) to train=true. </div><div class="line">This is useful for modules like Dropout that </div><div class="line">have a different behaviour during training vs evaluation.</div><div class="line">]]</div></pre></td></tr></table></figure></div><!-- comment system--><div class="container"><hr><div data-thread-key="2016/07/14/Torch7 doc/" data-title="Torch7 doc" data-url="http://www.sgq.mobi/2016/07/14/Torch7 doc/" class="ds-thread"></div><script>var duoshuoQuery = {short_name:'sgqmobi'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script></div></article><footer id="footer"><div class="container"><div class="bar"><div class="social"><a href="mailto:dad@sdz.red" target="_blank"><i class="fa fa-envelope-o"></i></a><a href="https://github.com/sohero" target="_blank"><i class="fa fa-github"></i></a></div><div class="footer">© 2017 <a href="/" rel="nofollow">Hero Memo</a>. Powered by <a rel="nofollow" target="_blank" href="https://hexo.io">Hexo</a>. Theme <a target="_blank" href="https://github.com/lotabout/very-simple">very-simple</a>.</div></div></div></footer><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
    $(".fancybox").fancybox();
});
</script></body></html>
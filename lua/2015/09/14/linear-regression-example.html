<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>linear regression example</title>
	
	<meta name="author" content="sohero">

	<!-- Enable responsive viewport -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
	<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<!-- Le styles -->
    <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css">
	<link href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
	<link href="/assets/css/syntax.css" rel="stylesheet">
	<link href="/assets/css/style.css" rel="stylesheet">

	<!-- Le fav and touch icons -->
	<link rel="shortcut icon" href="favicon.ico">
    <!-- Update these with your own images
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
	-->

	<link rel="alternate" type="application/rss+xml" title="" href="/feed.xml">
    <script type="text/javascript" src="http://static.blog.csdn.net/public/res/bower-libs/MathJax/MathJax.js?config=TeX-AMS_HTML"></script>
    
</head>

<body>
	<nav class="navbar navbar-default visible-xs" role="navigation">
		<!-- Brand and toggle get grouped for better mobile display -->
		<div class="navbar-header">
			<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
			
			<a type="button" class="navbar-toggle nav-link" href="http://github.com/sohero">
				<i class="fa fa-github"></i>
			</a>
			
			
			
			<a type="button" class="navbar-toggle nav-link" href="mailto:herosgq@gmail.com">
				<i class="fa fa-envelope"></i>
			</a>
			
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
			<ul class="nav navbar-nav">
				<li class="active"><a href="/">Home</a></li>
				<li><a href="/categories.html">Categories</a></li>
				<li><a href="/tags.html">Tags</a></li>
			</ul>
		</div><!-- /.navbar-collapse -->
	</nav>

	<!-- nav-menu-dropdown -->
	<div class="btn-group hidden-xs" id="nav-menu">
		<button type="button" class="btn btn-default dropdown-toggle" data-toggle="dropdown">
			<i class="fa fa-bars"></i>
		</button>
		<ul class="dropdown-menu" role="menu">
			<li><a href="/"><i class="fa fa-home"></i>Home</a></li>
			<li><a href="/categories.html"><i class="fa fa-folder"></i>Categories</a></li>
			<li><a href="/tags.html"><i class="fa fa-tags"></i>Tags</a></li>
			<li class="divider"></li>
			<li><a href="#"><i class="fa fa-arrow-up"></i>Top of Page</a></li>
		</ul>
	</div>

	<div class="col-sm-3 sidebar hidden-xs">
		<!-- sidebar.html -->
<header class="sidebar-header" role="banner">
	<a href="/">
		<img src="/assets/images/bl.png" class="img-circle" />
	</a>
	<h3 class="title">
        <a href="/"></a>
    </h3>
</header>


<div id="bio" class="text-center">
	An elder's memo.
</div>


<div id="contact-list" class="text-center">
	<ul class="list-unstyled list-inline">
		
		<li>
			<a class="btn btn-default btn-sm" href="https://github.com/sohero">
				<i class="fa fa-github-alt fa-lg"></i>
			</a>
		</li>
		
		
		<li>
			<a class="btn btn-default btn-sm" href="mailto:herosgq@gmail.com">
				<i class="fa fa-envelope fa-lg"></i>
			</a>
		</li>
		
        <li>
			<a class="btn btn-default btn-sm" href="/feed.xml">
				<i class="fa fa-rss fa-lg"></i>
			</a>
		</li>
	</ul>
</div>
<div style="width:171px;margin-left:auto;margin-right:auto;">
<script type="text/javascript">(function(){document.write(unescape('%3Cdiv id="bdcs"%3E%3C/div%3E'));var bdcs = document.createElement('script');bdcs.type = 'text/javascript';bdcs.async = true;bdcs.src = 'http://znsv.baidu.com/customer_search/api/js?sid=13267021605797832700' + '&plate_url=' + encodeURIComponent(window.location.href) + '&t=' + Math.ceil(new Date()/3600000);var s = document.getElementsByTagName('script')[0];s.parentNode.insertBefore(bdcs, s);})();</script>
</div>
<!-- sidebar.html end -->

	</div>

	<div class="col-sm-9 col-sm-offset-3">
		<div class="page-header">
  <h1>linear regression example </h1>
</div>
	
<article>

	<div class="col-sm-10">
	 <span class="post-date">
	 	2015-09-14 
	 </span>
	  <div class="article_body">
	  <div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua"><span class="co">----------------------------------------------------------------------</span>
<span class="co">-- example-linear-regression.lua</span>
<span class="co">-- </span>
<span class="co">-- This script provides a very simple step-by-step example of</span>
<span class="co">-- linear regression, using Torch7&#39;s neural network (nn) package,</span>
<span class="co">-- and the optimization package (optim).</span>
<span class="co">--</span>

<span class="co">-- note: to run this script, simply do:</span>
<span class="co">-- torch script.lua</span>

<span class="co">-- to run the script, and get an interactive shell once it terminates:</span>
<span class="co">-- torch -i script.lua</span>

<span class="co">-- we first require the necessary packages.</span>
<span class="co">-- note: optim is a 3rd-party package, and needs to be installed</span>
<span class="co">-- separately. This can be easily done using Torch7&#39;s package manager:</span>
<span class="co">-- torch-pkg install optim</span>

<span class="fu">require</span> <span class="st">&#39;torch&#39;</span>
<span class="fu">require</span> <span class="st">&#39;optim&#39;</span>
<span class="fu">require</span> <span class="st">&#39;nn&#39;</span>


<span class="co">----------------------------------------------------------------------</span>
<span class="co">-- 1. Create the training data</span>

<span class="co">-- In all regression problems, some training data needs to be </span>
<span class="co">-- provided. In a realistic scenarios, data comes from some database</span>
<span class="co">-- or file system, and needs to be loaded from disk. In that </span>
<span class="co">-- tutorial, we create the data source as a Lua table.</span>

<span class="co">-- In general, the data can be stored in arbitrary forms, and using</span>
<span class="co">-- Lua&#39;s flexible table data structure is usually a good idea. </span>
<span class="co">-- Here we store the data as a Torch Tensor (2D Array), where each</span>
<span class="co">-- row represents a training sample, and each column a variable. The</span>
<span class="co">-- first column is the target variable, and the others are the</span>
<span class="co">-- input variables.</span>

<span class="co">-- The data are from an example in Schaum&#39;s Outline:</span>
<span class="co">-- Dominick Salvator and Derrick Reagle</span>
<span class="co">-- Shaum&#39;s Outline of Theory and Problems of Statistics and Economics</span>
<span class="co">-- 2nd edition</span>
<span class="co">-- McGraw-Hill</span>
<span class="co">-- 2002</span>

<span class="co">-- The data relate the amount of corn produced, given certain amounts</span>
<span class="co">-- of fertilizer and insecticide. See p 157 of the text.</span>

<span class="co">-- In this example, we want to be able to predict the amount of</span>
<span class="co">-- corn produced, given the amount of fertilizer and intesticide used.</span>
<span class="co">-- In other words: fertilizer &amp; insecticide are our two input variables,</span>
<span class="co">-- and corn is our target value.</span>

<span class="co">--  {corn, fertilizer, insecticide}</span>
data <span class="ot">=</span> torch<span class="ot">.</span>Tensor<span class="ot">{</span>
   <span class="ot">{</span><span class="dv">40</span><span class="ot">,</span>  <span class="dv">6</span><span class="ot">,</span>  <span class="dv">4</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">44</span><span class="ot">,</span> <span class="dv">10</span><span class="ot">,</span>  <span class="dv">4</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">46</span><span class="ot">,</span> <span class="dv">12</span><span class="ot">,</span>  <span class="dv">5</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">48</span><span class="ot">,</span> <span class="dv">14</span><span class="ot">,</span>  <span class="dv">7</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">52</span><span class="ot">,</span> <span class="dv">16</span><span class="ot">,</span>  <span class="dv">9</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">58</span><span class="ot">,</span> <span class="dv">18</span><span class="ot">,</span> <span class="dv">12</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">60</span><span class="ot">,</span> <span class="dv">22</span><span class="ot">,</span> <span class="dv">14</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">68</span><span class="ot">,</span> <span class="dv">24</span><span class="ot">,</span> <span class="dv">20</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">74</span><span class="ot">,</span> <span class="dv">26</span><span class="ot">,</span> <span class="dv">21</span><span class="ot">},</span>
   <span class="ot">{</span><span class="dv">80</span><span class="ot">,</span> <span class="dv">32</span><span class="ot">,</span> <span class="dv">24</span><span class="ot">}</span>
<span class="ot">}</span>


<span class="co">----------------------------------------------------------------------</span>
<span class="co">-- 2. Define the model (predictor)</span>

<span class="co">-- The model will have one layer (called a module), which takes the </span>
<span class="co">-- 2 inputs (fertilizer and insecticide) and produces the 1 output </span>
<span class="co">-- (corn).</span>

<span class="co">-- Note that the Linear model specified below has 3 parameters:</span>
<span class="co">--   1 for the weight assigned to fertilizer</span>
<span class="co">--   1 for the weight assigned to insecticide</span>
<span class="co">--   1 for the weight assigned to the bias term</span>

<span class="co">-- In some other model specification schemes, one needs to augment the</span>
<span class="co">-- training data to include a constant value of 1, but this isn&#39;t done</span>
<span class="co">-- with the linear model.</span>

<span class="co">-- The linear model must be held in a container. A sequential container</span>
<span class="co">-- is appropriate since the outputs of each module become the inputs of </span>
<span class="co">-- the subsequent module in the model. In this case, there is only one</span>
<span class="co">-- module. In more complex cases, multiple modules can be stacked using</span>
<span class="co">-- the sequential container.</span>

<span class="co">-- The modules are all defined in the neural network package, which is</span>
<span class="co">-- named &#39;nn&#39;.</span>

model <span class="ot">=</span> nn<span class="ot">.</span>Sequential<span class="ot">()</span>                 <span class="co">-- define the container</span>
ninputs <span class="ot">=</span> <span class="dv">2</span><span class="ot">;</span> noutputs <span class="ot">=</span> <span class="dv">1</span>
model:add<span class="ot">(</span>nn<span class="ot">.</span>Linear<span class="ot">(</span>ninputs<span class="ot">,</span> noutputs<span class="ot">))</span> <span class="co">-- define the only module</span>


<span class="co">----------------------------------------------------------------------</span>
<span class="co">-- 3. Define a loss function, to be minimized.</span>

<span class="co">-- In that example, we minimize the Mean Square Error (MSE) between</span>
<span class="co">-- the predictions of our linear model and the groundtruth available</span>
<span class="co">-- in the dataset.</span>

<span class="co">-- Torch provides many common criterions to train neural networks.</span>

criterion <span class="ot">=</span> nn<span class="ot">.</span>MSECriterion<span class="ot">()</span>


<span class="co">----------------------------------------------------------------------</span>
<span class="co">-- 4. Train the model</span>

<span class="co">-- To minimize the loss defined above, using the linear model defined</span>
<span class="co">-- in &#39;model&#39;, we follow a stochastic gradient descent procedure (SGD).</span>

<span class="co">-- SGD is a good optimization algorithm when the amount of training data</span>
<span class="co">-- is large, and estimating the gradient of the loss function over the </span>
<span class="co">-- entire training set is too costly.</span>

<span class="co">-- Given an arbitrarily complex model, we can retrieve its trainable</span>
<span class="co">-- parameters, and the gradients of our loss function wrt these </span>
<span class="co">-- parameters by doing so:</span>

x<span class="ot">,</span> dl_dx <span class="ot">=</span> model:getParameters<span class="ot">()</span>

<span class="co">-- In the following code, we define a closure, feval, which computes</span>
<span class="co">-- the value of the loss function at a given point x, and the gradient of</span>
<span class="co">-- that function with respect to x. x is the vector of trainable weights,</span>
<span class="co">-- which, in this example, are all the weights of the linear matrix of</span>
<span class="co">-- our model, plus one bias.</span>

feval <span class="ot">=</span> <span class="kw">function</span><span class="ot">(</span>x_new<span class="ot">)</span>
   <span class="co">-- set x to x_new, if differnt</span>
   <span class="co">-- (in this simple example, x_new will typically always point to x,</span>
   <span class="co">-- so the copy is really useless)</span>
   <span class="kw">if</span> x <span class="ot">~=</span> x_new <span class="kw">then</span>
      x:copy<span class="ot">(</span>x_new<span class="ot">)</span>
   <span class="kw">end</span>

   <span class="co">-- select a new training sample</span>
   _nidx_ <span class="ot">=</span> <span class="ot">(</span>_nidx_ <span class="kw">or</span> <span class="dv">0</span><span class="ot">)</span> <span class="ot">+</span> <span class="dv">1</span>
   <span class="kw">if</span> _nidx_ <span class="ot">&gt;</span> <span class="ot">(#</span>data<span class="ot">)[</span><span class="dv">1</span><span class="ot">]</span> <span class="kw">then</span> _nidx_ <span class="ot">=</span> <span class="dv">1</span> <span class="kw">end</span>

   <span class="kw">local</span> sample <span class="ot">=</span> data<span class="ot">[</span>_nidx_<span class="ot">]</span>
   <span class="kw">local</span> target <span class="ot">=</span> sample<span class="ot">[{</span> <span class="ot">{</span><span class="dv">1</span><span class="ot">}</span> <span class="ot">}]</span>      <span class="co">-- this funny looking syntax allows</span>
   <span class="kw">local</span> inputs <span class="ot">=</span> sample<span class="ot">[{</span> <span class="ot">{</span><span class="dv">2</span><span class="ot">,</span><span class="dv">3</span><span class="ot">}</span> <span class="ot">}]</span>    <span class="co">-- slicing of arrays.</span>

   <span class="co">-- reset gradients (gradients are always accumulated, to accomodate </span>
   <span class="co">-- batch methods)</span>
   dl_dx:zero<span class="ot">()</span>

   <span class="co">-- evaluate the loss function and its derivative wrt x, for that sample</span>
   <span class="kw">local</span> loss_x <span class="ot">=</span> criterion:forward<span class="ot">(</span>model:forward<span class="ot">(</span>inputs<span class="ot">),</span> target<span class="ot">)</span>
   model:backward<span class="ot">(</span>inputs<span class="ot">,</span> criterion:backward<span class="ot">(</span>model<span class="ot">.</span>output<span class="ot">,</span> target<span class="ot">))</span>

   <span class="co">-- return loss(x) and dloss/dx</span>
   <span class="kw">return</span> loss_x<span class="ot">,</span> dl_dx
<span class="kw">end</span>

<span class="co">-- Given the function above, we can now easily train the model using SGD.</span>
<span class="co">-- For that, we need to define four key parameters:</span>
<span class="co">--   + a learning rate: the size of the step taken at each stochastic </span>
<span class="co">--     estimate of the gradient</span>
<span class="co">--   + a weight decay, to regularize the solution (L2 regularization)</span>
<span class="co">--   + a momentum term, to average steps over time</span>
<span class="co">--   + a learning rate decay, to let the algorithm converge more precisely</span>

sgd_params <span class="ot">=</span> <span class="ot">{</span>
   learningRate <span class="ot">=</span> <span class="dv">1e-3</span><span class="ot">,</span>
   learningRateDecay <span class="ot">=</span> <span class="dv">1e-4</span><span class="ot">,</span>
   weightDecay <span class="ot">=</span> <span class="dv">0</span><span class="ot">,</span>
   momentum <span class="ot">=</span> <span class="dv">0</span>
<span class="ot">}</span>

<span class="co">-- We&#39;re now good to go... all we have left to do is run over the dataset</span>
<span class="co">-- for a certain number of iterations, and perform a stochastic update </span>
<span class="co">-- at each iteration. The number of iterations is found empirically here,</span>
<span class="co">-- but should typically be determinined using cross-validation.</span>

<span class="co">-- we cycle 1e4 times over our training data</span>
<span class="kw">for</span> i <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">1e4</span> <span class="kw">do</span>

   <span class="co">-- this variable is used to estimate the average loss</span>
   current_loss <span class="ot">=</span> <span class="dv">0</span>

   <span class="co">-- an epoch is a full loop over our training data</span>
   <span class="kw">for</span> i <span class="ot">=</span> <span class="dv">1</span><span class="ot">,(#</span>data<span class="ot">)[</span><span class="dv">1</span><span class="ot">]</span> <span class="kw">do</span>

      <span class="co">-- optim contains several optimization algorithms. </span>
      <span class="co">-- All of these algorithms assume the same parameters:</span>
      <span class="co">--   + a closure that computes the loss, and its gradient wrt to x, </span>
      <span class="co">--     given a point x</span>
      <span class="co">--   + a point x</span>
      <span class="co">--   + some parameters, which are algorithm-specific</span>
      
      _<span class="ot">,</span>fs <span class="ot">=</span> optim<span class="ot">.</span>sgd<span class="ot">(</span>feval<span class="ot">,</span>x<span class="ot">,</span>sgd_params<span class="ot">)</span>

      <span class="co">-- Functions in optim all return two things:</span>
      <span class="co">--   + the new x, found by the optimization method (here SGD)</span>
      <span class="co">--   + the value of the loss functions at all points that were used by</span>
      <span class="co">--     the algorithm. SGD only estimates the function once, so</span>
      <span class="co">--     that list just contains one value.</span>

      current_loss <span class="ot">=</span> current_loss <span class="ot">+</span> fs<span class="ot">[</span><span class="dv">1</span><span class="ot">]</span>
   <span class="kw">end</span>

   <span class="co">-- report average error on epoch</span>
   current_loss <span class="ot">=</span> current_loss <span class="ot">/</span> <span class="ot">(#</span>data<span class="ot">)[</span><span class="dv">1</span><span class="ot">]</span>
   <span class="fu">print</span><span class="ot">(</span><span class="st">&#39;current loss = &#39;</span> <span class="ot">..</span> current_loss<span class="ot">)</span>

<span class="kw">end</span>


<span class="co">----------------------------------------------------------------------</span>
<span class="co">-- 5. Test the trained model.</span>

<span class="co">-- Now that the model is trained, one can test it by evaluating it</span>
<span class="co">-- on new samples.</span>

<span class="co">-- The text solves the model exactly using matrix techniques and determines</span>
<span class="co">-- that </span>
<span class="co">--   corn = 31.98 + 0.65 * fertilizer + 1.11 * insecticides</span>

<span class="co">-- We compare our approximate results with the text&#39;s results.</span>

text <span class="ot">=</span> <span class="ot">{</span><span class="dv">40.32</span><span class="ot">,</span> <span class="dv">42.92</span><span class="ot">,</span> <span class="dv">45.33</span><span class="ot">,</span> <span class="dv">48.85</span><span class="ot">,</span> <span class="dv">52.37</span><span class="ot">,</span> <span class="dv">57</span><span class="ot">,</span> <span class="dv">61.82</span><span class="ot">,</span> <span class="dv">69.78</span><span class="ot">,</span> <span class="dv">72.19</span><span class="ot">,</span> <span class="dv">79.42</span><span class="ot">}</span>

<span class="fu">print</span><span class="ot">(</span><span class="st">&#39;id  approx   text&#39;</span><span class="ot">)</span>
<span class="kw">for</span> i <span class="ot">=</span> <span class="dv">1</span><span class="ot">,(#</span>data<span class="ot">)[</span><span class="dv">1</span><span class="ot">]</span> <span class="kw">do</span>
   <span class="kw">local</span> myPrediction <span class="ot">=</span> model:forward<span class="ot">(</span>data<span class="ot">[</span>i<span class="ot">][</span><span class="dv">2</span><span class="ot">])</span>
   <span class="fu">print</span><span class="ot">(</span><span class="fu">string.format</span><span class="ot">(</span><span class="st">&quot;%2d  %6.2f %6.2f&quot;</span><span class="ot">,</span> i<span class="ot">,</span> myPrediction<span class="ot">[</span><span class="dv">1</span><span class="ot">],</span> text<span class="ot">[</span>i<span class="ot">]))</span>
<span class="kw">end</span></code></pre></div>

	  </div>

		
		<ul class="tag_box list-unstyled list-inline">
		  <li><i class="fa fa-folder-open"></i></li>
		  
		  
			 
				<li><a href="/categories.html#lua-ref">
					lua <span>(10)</span>
					
				</a></li>
			
		  
		</ul>
		  

		
		<ul class="list-inline">
		  <li><i class="fa fa-tags"></i></li>
		  
		  
			 
				<li>
					<a href="/tags.html#lua-ref">
					lua <span>(10)</span>
					
					</a>
				</li>
			
		  
		  
		</ul>
		  

		<hr>

		<div>
      <section class="share col-sm-12">
        <h4 class="section-title">Share Post</h4>
        <a class="btn btn-default btn-sm twitter" href="http://twitter.com/share?text=linear regression example"
           onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
          <i class="fa fa-twitter fa-lg"></i>
          Twitter
        </a>
        <a class="btn btn-default btn-sm facebook" href="https://www.facebook.com/sharer/sharer.php"
           onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
          <i class="fa fa-facebook fa-lg"></i>
          Facebook
        </a>
        <a class="btn btn-default btn-sm gplus"
           onclick="window.open('https://plus.google.com/share?url='+window.location.href, 'google-plus-share', 'width=490,height=530');return false;">
          <i class="fa fa-google-plus fa-lg"></i>
          Google+
        </a>
      </section>
    </div>

    <div class="clearfix"></div>

		<ul class="pager">
		  
		  <li class="previous"><a href="/foundation/2015/09/04/improving-the-way-neural-networks-learn.html" title="Improving the way neural networks learn">&larr; Previous</a></li>
		  
		  
		  <li class="next"><a href="/foundation/2015/10/22/determinant.html" title="Determinant">Next &rarr;</a></li>
		  
		</ul>

		<hr>
	</div>
	
	<div class="col-sm-2 sidebar-2">
	
	</div>
</article>
<div class="clearfix"></div>





		<footer>
			<hr/>
			<p>
				&copy; 2015 <a href="http://guoqiang.gq">sohero</a>.
			</p>
		</footer>
	</div>

	<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script>
	<script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="/assets/js/app.js"></script>
</body>
</html>




<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>Torch7 doc</title>
	
	<meta name="author" content="sohero">

	<!-- Enable responsive viewport -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
	<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<!-- Le styles -->
    <link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css">
	<link href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
	<link href="/assets/css/syntax.css" rel="stylesheet">
	<link href="/assets/css/style.css" rel="stylesheet">

	<!-- Le fav and touch icons -->
	<link rel="shortcut icon" href="favicon.ico">
    <!-- Update these with your own images
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
	-->

	<link rel="alternate" type="application/rss+xml" title="" href="/feed.xml">
    <script type="text/javascript" src="http://static.blog.csdn.net/public/res/bower-libs/MathJax/MathJax.js?config=TeX-AMS_HTML"></script>
    
</head>

<body>
	<nav class="navbar navbar-default visible-xs" role="navigation">
		<!-- Brand and toggle get grouped for better mobile display -->
		<div class="navbar-header">
			<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
			
			<a type="button" class="navbar-toggle nav-link" href="http://github.com/sohero">
				<i class="fa fa-github"></i>
			</a>
			
			
			
			<a type="button" class="navbar-toggle nav-link" href="mailto:herosgq@gmail.com">
				<i class="fa fa-envelope"></i>
			</a>
			
            <input type="text" class="st-default-search-input navbar-toggle" style="width:100px;">
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
			<ul class="nav navbar-nav">
				<li class="active"><a href="/">Home</a></li>
				<li><a href="/categories.html">Categories</a></li>
				<li><a href="/tags.html">Tags</a></li>
			</ul>
		</div><!-- /.navbar-collapse -->
	</nav>

	<!-- nav-menu-dropdown -->
	<div class="btn-group hidden-xs" id="nav-menu">
		<button type="button" class="btn btn-default dropdown-toggle" data-toggle="dropdown">
			<i class="fa fa-bars"></i>
		</button>
		<ul class="dropdown-menu" role="menu">
			<li><a href="/"><i class="fa fa-home"></i>Home</a></li>
			<li><a href="/categories.html"><i class="fa fa-folder"></i>Categories</a></li>
			<li><a href="/tags.html"><i class="fa fa-tags"></i>Tags</a></li>
			<li class="divider"></li>
			<li><a href="#"><i class="fa fa-arrow-up"></i>Top of Page</a></li>
		</ul>
	</div>

	<div class="col-sm-3 sidebar hidden-xs">
		<!-- sidebar.html -->
<header class="sidebar-header" role="banner">
	<a href="/">
		<img src="/assets/images/bl.png" class="img-circle" />
	</a>
	<h3 class="title">
        <a href="/"></a>
    </h3>
</header>


<div id="bio" class="text-center">
	An elder's memo.
</div>


<div id="contact-list" class="text-center">
	<ul class="list-unstyled list-inline">
		
		<li>
			<a class="btn btn-default btn-sm" href="https://github.com/sohero">
				<i class="fa fa-github-alt fa-lg"></i>
			</a>
		</li>
		
		
		<li>
			<a class="btn btn-default btn-sm" href="mailto:herosgq@gmail.com">
				<i class="fa fa-envelope fa-lg"></i>
			</a>
		</li>
		
        <li>
			<a class="btn btn-default btn-sm" href="/feed.xml">
				<i class="fa fa-rss fa-lg"></i>
			</a>
		</li>
	</ul>
</div>
<div style="width:171px;margin-left:auto;margin-right:auto;">
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','ajvL7F6K122b67uo9oa2','2.0.0');
</script>
<input type="text" class="st-default-search-input" style="width:130px;">
</div>
<!-- sidebar.html end -->

	</div>

	<div class="col-sm-9 col-sm-offset-3">
		<div class="page-header">
  <h1>Torch7 doc </h1>
</div>
	
<article>

	<div class="col-sm-10">
	 <span class="post-date">
	 	2015-08-28 
	 </span>
	  <div class="article_body">
	  <h2 id="torch">torch</h2>
<h3 id="res-torch.clampres-tensor1-min_value-max_value">[res] torch.clamp([res,] tensor1, min_value, max_value)</h3>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua"><span class="co">--[[</span>
<span class="co">Clamp all elements in the tensor into the range [min_value, max_value].</span>
<span class="co">ie:</span>
<span class="co">    y_i = x_i,  if x_i &gt;= min_value or x_i &lt;= max_value</span>
<span class="co">    y_i = min_value,  if x_i </span><span class="kw">&lt; min_value</span>
<span class="ot">    y_i = </span>max<span class="ot">_value,  if x_i </span><span class="kw">&gt;</span><span class="co"> max_value </span>

<span class="co">z=torch.clamp(x,0,1) will return a new tensor </span>
<span class="co">with the result of x bounded between 0 and 1.</span>

<span class="co">torch.clamp(z,x,0,1) will put the result in z .</span>

<span class="co">x:clamp(0,1) will perform the clamp operation in place</span>
<span class="co">(putting the result in x ).</span>

<span class="co"> z:clamp(x,0,1) will put the result in z .  </span>
<span class="co"> ]]</span></code></pre></div>
<h2 id="nn">nn</h2>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua">nn<span class="ot">.</span>SplitTable<span class="ot">()</span>    <span class="co">-- (N)dim Tensor -&gt; table of (N-1)dim Tensors</span>
nn<span class="ot">.</span>JoinTable<span class="ot">()</span>    <span class="co">-- table of (N-1)dim Tensors -&gt; (N)dim Tensor</span>
<span class="co">--[[</span>
<span class="co">This function returns noutput number of new nodes </span>
<span class="co">that each take a single component of the output of this </span>
<span class="co">node in the order they are returned.</span>
<span class="co">]]</span>
nngraph<span class="ot">.</span>Node:split<span class="ot">(</span>noutput<span class="ot">)</span></code></pre></div>
<h2 id="torch.tensor">torch.Tensor</h2>
<h3 id="result-viewresult-tensor-sizes">[result] view([result,] tensor, sizes)</h3>
<p>Creates a view with different dimensions of the storage associated with <code>tensor</code>. If <code>result</code> is not passed, then a new tensor is returned, otherwise its storage is made to point to storage of <code>tensor</code>.</p>
<p><code>sizes</code> can either be a <code>torch.LongStorage</code> or numbers. If one of the dimensions is -1, the size of that dimension is inferred from the rest of the elements.</p>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua">x <span class="ot">=</span> torch<span class="ot">.</span>zeros<span class="ot">(</span><span class="dv">4</span><span class="ot">)</span>
<span class="ot">&gt;</span> x:view<span class="ot">(</span><span class="dv">2</span><span class="ot">,</span><span class="dv">2</span><span class="ot">)</span>
 <span class="dv">0</span> <span class="dv">0</span>
 <span class="dv">0</span> <span class="dv">0</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 2x2<span class="ot">]</span>

<span class="ot">&gt;</span> x:view<span class="ot">(</span><span class="dv">2</span><span class="ot">,-</span><span class="dv">1</span><span class="ot">)</span>
 <span class="dv">0</span> <span class="dv">0</span>
 <span class="dv">0</span> <span class="dv">0</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 2x2<span class="ot">]</span>

<span class="ot">&gt;</span> x:view<span class="ot">(</span>torch<span class="ot">.</span>LongStorage<span class="ot">{</span><span class="dv">2</span><span class="ot">,</span><span class="dv">2</span><span class="ot">})</span>
 <span class="dv">0</span> <span class="dv">0</span>
 <span class="dv">0</span> <span class="dv">0</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 2x2<span class="ot">]</span>

<span class="ot">&gt;</span> x
 <span class="dv">0</span>
 <span class="dv">0</span>
 <span class="dv">0</span>
 <span class="dv">0</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension <span class="dv">4</span><span class="ot">]</span></code></pre></div>
<h3 id="result-splitresult-tensor-size-dim">[result] split([result,] tensor, size, [dim])</h3>
<p>Splits Tensor <code>tensor</code> along dimension <code>dim</code> into a <code>result</code> table of Tensors of size <code>size</code> (a number) or less (in the case of the last Tensor). The sizes of the non-<code>dim</code> dimensions remain unchanged. Internally, a series of <a href="#torch.Tensor.narrow">narrows</a> are performed along dimensions <code>dim</code>. Argument <code>dim</code> defaults to 1.</p>
<p>If <code>result</code> is not passed, then a new table is returned, otherwise it is emptied and reused.</p>
<p>Example:</p>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua">x <span class="ot">=</span> torch<span class="ot">.</span>randn<span class="ot">(</span><span class="dv">3</span><span class="ot">,</span><span class="dv">4</span><span class="ot">,</span><span class="dv">5</span><span class="ot">)</span>

<span class="ot">&gt;</span> x:split<span class="ot">(</span><span class="dv">2</span><span class="ot">,</span><span class="dv">1</span><span class="ot">)</span>
<span class="ot">{</span>
  <span class="dv">1</span> : DoubleTensor <span class="ot">-</span> size: 2x4x5
  <span class="dv">2</span> : DoubleTensor <span class="ot">-</span> size: 1x4x5
<span class="ot">}</span>

<span class="ot">&gt;</span> x:split<span class="ot">(</span><span class="dv">3</span><span class="ot">,</span><span class="dv">2</span><span class="ot">)</span>
<span class="ot">{</span>
  <span class="dv">1</span> : DoubleTensor <span class="ot">-</span> size: 3x3x5
  <span class="dv">2</span> : DoubleTensor <span class="ot">-</span> size: 3x1x5
<span class="ot">}</span>

<span class="ot">&gt;</span> x:split<span class="ot">(</span><span class="dv">2</span><span class="ot">,</span><span class="dv">3</span><span class="ot">)</span>
<span class="ot">{</span>
  <span class="dv">1</span> : DoubleTensor <span class="ot">-</span> size: 3x4x2
  <span class="dv">2</span> : DoubleTensor <span class="ot">-</span> size: 3x4x2
  <span class="dv">3</span> : DoubleTensor <span class="ot">-</span> size: 3x4x1
<span class="ot">}</span></code></pre></div>
<h3 id="tensor-indexdim-index">[Tensor] index(dim, index)</h3>
<p>Returns a new <code>Tensor</code> which indexes the original <code>Tensor</code> along dimension <code>dim</code> using the entries in <code>torch.LongTensor</code> <code>index</code>. The returned <code>Tensor</code> has the same number of dimensions as the original <code>Tensor</code>. The returned <code>Tensor</code> does <strong>not</strong> use the same storage as the original <code>Tensor</code> â€“ see below for storing the result in an existing <code>Tensor</code>.</p>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua">x <span class="ot">=</span> torch<span class="ot">.</span>rand<span class="ot">(</span><span class="dv">5</span><span class="ot">,</span><span class="dv">5</span><span class="ot">)</span>
<span class="ot">&gt;</span> x
 <span class="dv">0.8020</span>  <span class="dv">0.7246</span>  <span class="dv">0.1204</span>  <span class="dv">0.3419</span>  <span class="dv">0.4385</span>
 <span class="dv">0.0369</span>  <span class="dv">0.4158</span>  <span class="dv">0.0985</span>  <span class="dv">0.3024</span>  <span class="dv">0.8186</span>
 <span class="dv">0.2746</span>  <span class="dv">0.9362</span>  <span class="dv">0.2546</span>  <span class="dv">0.8586</span>  <span class="dv">0.6674</span>
 <span class="dv">0.7473</span>  <span class="dv">0.9028</span>  <span class="dv">0.1046</span>  <span class="dv">0.9085</span>  <span class="dv">0.6622</span>
 <span class="dv">0.1412</span>  <span class="dv">0.6784</span>  <span class="dv">0.1624</span>  <span class="dv">0.8113</span>  <span class="dv">0.3949</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 5x5<span class="ot">]</span>

y <span class="ot">=</span> x:index<span class="ot">(</span><span class="dv">1</span><span class="ot">,</span>torch<span class="ot">.</span>LongTensor<span class="ot">{</span><span class="dv">3</span><span class="ot">,</span><span class="dv">1</span><span class="ot">})</span>
<span class="ot">&gt;</span> y
 <span class="dv">0.2746</span>  <span class="dv">0.9362</span>  <span class="dv">0.2546</span>  <span class="dv">0.8586</span>  <span class="dv">0.6674</span>
 <span class="dv">0.8020</span>  <span class="dv">0.7246</span>  <span class="dv">0.1204</span>  <span class="dv">0.3419</span>  <span class="dv">0.4385</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 2x5<span class="ot">]</span>

y:fill<span class="ot">(</span><span class="dv">1</span><span class="ot">)</span>
<span class="ot">&gt;</span> y
 <span class="dv">1</span>  <span class="dv">1</span>  <span class="dv">1</span>  <span class="dv">1</span>  <span class="dv">1</span>
 <span class="dv">1</span>  <span class="dv">1</span>  <span class="dv">1</span>  <span class="dv">1</span>  <span class="dv">1</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 2x5<span class="ot">]</span>

<span class="ot">&gt;</span> x
 <span class="dv">0.8020</span>  <span class="dv">0.7246</span>  <span class="dv">0.1204</span>  <span class="dv">0.3419</span>  <span class="dv">0.4385</span>
 <span class="dv">0.0369</span>  <span class="dv">0.4158</span>  <span class="dv">0.0985</span>  <span class="dv">0.3024</span>  <span class="dv">0.8186</span>
 <span class="dv">0.2746</span>  <span class="dv">0.9362</span>  <span class="dv">0.2546</span>  <span class="dv">0.8586</span>  <span class="dv">0.6674</span>
 <span class="dv">0.7473</span>  <span class="dv">0.9028</span>  <span class="dv">0.1046</span>  <span class="dv">0.9085</span>  <span class="dv">0.6622</span>
 <span class="dv">0.1412</span>  <span class="dv">0.6784</span>  <span class="dv">0.1624</span>  <span class="dv">0.8113</span>  <span class="dv">0.3949</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 5x5<span class="ot">]</span></code></pre></div>
<p>Note the explicit <code>index</code> function is different than the indexing operator <code>[]</code>. The indexing operator <code>[]</code> is a syntactic shortcut for a series of select and narrow operations, therefore it always returns a new view on the original tensor that shares the same storage. However, the explicit <code>index</code> function can not use the same storage.</p>
<p>It is possible to store the result into an existing Tensor with <code>result:index(source, ...)</code>:</p>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua">x <span class="ot">=</span> torch<span class="ot">.</span>rand<span class="ot">(</span><span class="dv">5</span><span class="ot">,</span><span class="dv">5</span><span class="ot">)</span>
<span class="ot">&gt;</span> x
 <span class="dv">0.8020</span>  <span class="dv">0.7246</span>  <span class="dv">0.1204</span>  <span class="dv">0.3419</span>  <span class="dv">0.4385</span>
 <span class="dv">0.0369</span>  <span class="dv">0.4158</span>  <span class="dv">0.0985</span>  <span class="dv">0.3024</span>  <span class="dv">0.8186</span>
 <span class="dv">0.2746</span>  <span class="dv">0.9362</span>  <span class="dv">0.2546</span>  <span class="dv">0.8586</span>  <span class="dv">0.6674</span>
 <span class="dv">0.7473</span>  <span class="dv">0.9028</span>  <span class="dv">0.1046</span>  <span class="dv">0.9085</span>  <span class="dv">0.6622</span>
 <span class="dv">0.1412</span>  <span class="dv">0.6784</span>  <span class="dv">0.1624</span>  <span class="dv">0.8113</span>  <span class="dv">0.3949</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 5x5<span class="ot">]</span>

y <span class="ot">=</span> torch<span class="ot">.</span>Tensor<span class="ot">()</span>
y:index<span class="ot">(</span>x<span class="ot">,</span><span class="dv">1</span><span class="ot">,</span>torch<span class="ot">.</span>LongTensor<span class="ot">{</span><span class="dv">3</span><span class="ot">,</span><span class="dv">1</span><span class="ot">})</span>
<span class="ot">&gt;</span> y
 <span class="dv">0.2746</span>  <span class="dv">0.9362</span>  <span class="dv">0.2546</span>  <span class="dv">0.8586</span>  <span class="dv">0.6674</span>
 <span class="dv">0.8020</span>  <span class="dv">0.7246</span>  <span class="dv">0.1204</span>  <span class="dv">0.3419</span>  <span class="dv">0.4385</span>
<span class="ot">[</span>torch<span class="ot">.</span>DoubleTensor of dimension 2x5<span class="ot">]</span></code></pre></div>
<h2 id="nn.module">nn.Module</h2>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua">:training<span class="ot">()</span>
<span class="co">--[[</span>
<span class="co">This sets the mode of the Module (or sub-modules) to train=true. </span>
<span class="co">This is useful for modules like Dropout that </span>
<span class="co">have a different behaviour during training vs evaluation.</span>
<span class="co">]]</span></code></pre></div>

	  </div>

		
		<ul class="tag_box list-unstyled list-inline">
		  <li><i class="fa fa-folder-open"></i></li>
		  
		  
			 
				<li><a href="/categories.html#lua-ref">
					lua <span>(10)</span>
					
				</a></li>
			
		  
		</ul>
		  

		
		<ul class="list-inline">
		  <li><i class="fa fa-tags"></i></li>
		  
		  
			 
				<li>
					<a href="/tags.html#lua-ref">
					lua <span>(10)</span>
					
					</a>
				</li>
			
		  
		  
		</ul>
		  

		<hr>

		<div>
      <section class="share col-sm-12">
        <h4 class="section-title">Share Post</h4>
        <a class="btn btn-default btn-sm twitter" href="http://twitter.com/share?text=Torch7 doc"
           onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
          <i class="fa fa-twitter fa-lg"></i>
          Twitter
        </a>
        <a class="btn btn-default btn-sm facebook" href="https://www.facebook.com/sharer/sharer.php"
           onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
          <i class="fa fa-facebook fa-lg"></i>
          Facebook
        </a>
        <a class="btn btn-default btn-sm gplus"
           onclick="window.open('https://plus.google.com/share?url='+window.location.href, 'google-plus-share', 'width=490,height=530');return false;">
          <i class="fa fa-google-plus fa-lg"></i>
          Google+
        </a>
      </section>
    </div>

    <div class="clearfix"></div>

		<ul class="pager">
		  
		  <li class="previous"><a href="/foundation/2015/08/22/lstm.html" title="LSTM">&larr; Previous</a></li>
		  
		  
		  <li class="next"><a href="/foundation/2015/08/31/gated-recurrent-units-gru.html" title="Gated Recurrent Units (GRU)">Next &rarr;</a></li>
		  
		</ul>

		<hr>
	</div>
	
	<div class="col-sm-2 sidebar-2">
	
	</div>
</article>
<div class="clearfix"></div>
<script>
(function(){
    var bp = document.createElement('script');
    bp.src = '//push.zhanzhang.baidu.com/push.js';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>




		<footer>
			<hr/>
			<p>
				&copy; 2016 <a href="http://guoqiang.gq">sohero</a>.
			</p>
		</footer>
	</div>

	<script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"></script>
	<script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="/assets/js/app.js"></script>
</body>
</html>



